{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing the nuScenes Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This notebook introduces the nuScenes dataset and visualizes the information relevant for the trajectory prediction task.  \n",
    "We explore:\n",
    "\n",
    "- Dataset structure (JSON tables)\n",
    "- Sensor data (camera + lidar)\n",
    "- HD maps (drivable area)\n",
    "- Past and future trajectories of agents\n",
    "- Rasterized input representation used by the MTP model\n",
    "- Agent State Vector (velocity, acceleration, heading-rate)\n",
    "\n",
    "nuScenes is a large multimodal dataset, but for prediction we only use a very specific subset of information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "current_path = Path(os.getcwd())\n",
    "project_root = current_path.parent\n",
    "\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.append(str(project_root))\n",
    "\n",
    "try:\n",
    "    import nuimages \n",
    "    import nuscenes\n",
    "    print(\"nuimages and nuscenes imported\")\n",
    "except ImportError as e:\n",
    "    print(f\"error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we import all the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import pickle\n",
    "from nuscenes import NuScenes\n",
    "import os\n",
    "import json\n",
    "from nuscenes.map_expansion.map_api import NuScenesMap\n",
    "\n",
    "from pyquaternion import Quaternion\n",
    "from nuscenes.utils.geometry_utils import transform_matrix\n",
    "from nuscenes import NuScenes\n",
    "from nuscenes.prediction import PredictHelper\n",
    "from nuscenes.eval.prediction.config import load_prediction_config\n",
    "from nuscenes.eval.prediction.compute_metrics import compute_metrics\n",
    "import torch\n",
    "import numpy as np\n",
    "from pyquaternion import Quaternion\n",
    "from nuscenes.eval.prediction.data_classes import Prediction\n",
    "from nuscenes.eval.prediction.compute_metrics import compute_metrics\n",
    "from nuscenes.prediction.models.physics import ConstantVelocityHeading, PhysicsOracle\n",
    "from nuscenes.eval.prediction.data_classes import Prediction\n",
    "\n",
    "from nuscenes import NuScenes\n",
    "from nuscenes.prediction import PredictHelper\n",
    "from nuscenes.eval.prediction.data_classes import Prediction\n",
    "from nuscenes.eval.prediction.metrics import MinADEK, MinFDEK, RowMean\n",
    "from nuscenes.prediction.models.backbone import ResNetBackbone\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from nuscenes.eval.prediction.config import load_prediction_config\n",
    "from nuscenes.eval.prediction.compute_metrics import compute_metrics\n",
    "from nuscenes.prediction.models.backbone import ResNetBackbone\n",
    "from nuscenes.prediction.input_representation.static_layers import StaticLayerRasterizer\n",
    "from nuscenes.prediction.input_representation.agents import AgentBoxesWithFadedHistory\n",
    "from nuscenes.prediction.input_representation.interface import InputRepresentation\n",
    "from nuscenes.prediction.input_representation.combinators import Rasterizer\n",
    "\n",
    "from nuscenes.eval.prediction.config import load_prediction_config\n",
    "from nuscenes.eval.prediction.splits import get_prediction_challenge_split\n",
    "from nuscenes.prediction import PredictHelper\n",
    "from nuscenes.prediction.models.physics import ConstantVelocityHeading, PhysicsOracle\n",
    "\n",
    "from nuscenes.map_expansion import arcline_path_utils\n",
    "from nuscenes.prediction.models.backbone import ResNetBackbone\n",
    "from nuscenes.prediction.models.mtp import MTP\n",
    "from nuscenes.prediction.models.covernet import CoverNet\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from nuscenes.prediction.models.mtp import MTPLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATAROOT = '/root/nuscenes-devkit/data/sets/nuscenes'\n",
    "\n",
    "nuscenes = NuScenes('v1.0-mini', dataroot=DATAROOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary of dataset size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of scenes:\", len(nuscenes.scene))\n",
    "print(\"Number of annotations:\", len(nuscenes.sample_annotation))\n",
    "print(\"Number of keyframe samples:\", len(nuscenes.sample))\n",
    "print(\"Number of tracked instances:\", len(nuscenes.instance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List all JSON metadata files in v1.0-mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version_dir = os.path.join(DATAROOT, \"v1.0-mini\")\n",
    "json_files = [f for f in os.listdir(version_dir) if f.endswith(\".json\")]\n",
    "\n",
    "print(\"JSON files available in v1.0-mini:\\n\")\n",
    "for f in json_files:\n",
    "    print(\" -\", f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preview of the structure of the key JSON tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_json_keys(filename, n=5):\n",
    "    print(f\"\\nInside file: {filename}:\")\n",
    "    path = os.path.join(version_dir, filename)\n",
    "    data = json.load(open(path))\n",
    "    for key in data[0]:\n",
    "        print(\" •\", key)\n",
    "    print(f\"Example:\\n{data[0]}\")\n",
    "    \n",
    "show_json_keys(\"sample.json\")\n",
    "show_json_keys(\"sample_annotation.json\")\n",
    "show_json_keys(\"instance.json\")\n",
    "show_json_keys(\"ego_pose.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visuallization of sensors of a scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuscenes.render_sample_data(nuscenes.sample[0]['data']['CAM_FRONT'])\n",
    "nuscenes.render_sample_data(nuscenes.sample[0]['data']['LIDAR_TOP'])\n",
    "nuscenes.render_sample_data(nuscenes.sample[0]['data']['RADAR_FRONT'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization of drivable area map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_token = nuscenes.sample[0]['token']\n",
    "log = nuscenes.get('log', nuscenes.get('scene', nuscenes.sample[0]['scene_token'])['log_token'])\n",
    "map_name = log['location']\n",
    "nmap = NuScenesMap(dataroot=DATAROOT, map_name=map_name)\n",
    "\n",
    "nmap.render_map_in_image(nusc=nuscenes, sample_token=sample_token, layer_names=['road_segment', 'lane', 'ped_crossing'], alpha=0.3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Past and future trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper = PredictHelper(nuscenes)\n",
    "\n",
    "sample_token = nuscenes.sample[20]['token']\n",
    "anns = nuscenes.sample[20]['anns']\n",
    "instance_token = nuscenes.get('sample_annotation', anns[0])['instance_token']\n",
    "\n",
    "past = helper.get_past_for_agent(instance_token, sample_token, 2, in_agent_frame=False)\n",
    "future = helper.get_future_for_agent(instance_token, sample_token, 6, in_agent_frame=False)\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.plot(past[:,0], past[:,1], 'bo-', label=\"Past\")\n",
    "plt.plot(future[:,0], future[:,1], 'ro-', label=\"Future (GT)\")\n",
    "plt.legend()\n",
    "plt.title(\"Trajectory of the agent (past and future)\")\n",
    "plt.grid()\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input representation for trajectory prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input to a model is the tensor that encodes: \n",
    "\n",
    "- the **static semantic map** (drivable area, walkways, lanes),\n",
    "- the **past motion of nearby agents**, and\n",
    "- the **target agent’s position**.\n",
    "\n",
    "Different papers use different ways of building this tensor.  \n",
    "For example:\n",
    "\n",
    "- **CoverNet** and **MTP** rasterize the scene into a 3-channel RGB image.  \n",
    "- **Rules of the Road** uses a deeper tensor with many semantic channels.\n",
    "\n",
    "nuScenes provides a flexible module called `input_representation` that makes it\n",
    "easy to construct these tensors. An input representation consists of:\n",
    "\n",
    "1. **StaticLayerRepresentation** — how the static map is drawn  \n",
    "2. **AgentRepresentation** — how surrounding agents and their history are drawn  \n",
    "3. **Combinator** — how both sources are merged into a single tensor  \n",
    "\n",
    "The MTP model uses a rasterized bird’s-eye-view image combining static layers and\n",
    "agent boxes. Below we generate the exact raster input used by MTP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_layer_rasterizer = StaticLayerRasterizer(helper)\n",
    "agent_rasterizer = AgentBoxesWithFadedHistory(helper, seconds_of_history=1)\n",
    "mtp_input_representation = InputRepresentation(static_layer_rasterizer, agent_rasterizer, Rasterizer())\n",
    "\n",
    "instance_token_img, sample_token_img = 'bc38961ca0ac4b14ab90e547ba79fbb6', '7626dde27d604ac28a0240bdd54eba7a'\n",
    "anns = [ann for ann in nuscenes.sample_annotation if ann['instance_token'] == instance_token_img]\n",
    "img = mtp_input_representation.make_input_representation(instance_token_img, sample_token_img)\n",
    "\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization of rasterization that model uses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_layer_rasterizer = StaticLayerRasterizer(helper)\n",
    "agent_rasterizer = AgentBoxesWithFadedHistory(helper, seconds_of_history=1)\n",
    "mtp_input_representation = InputRepresentation(static_layer_rasterizer, agent_rasterizer, Rasterizer())\n",
    "\n",
    "img = mtp_input_representation.make_input_representation(instance_token, sample_token)\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(img)\n",
    "plt.title(\"Raster used as input for MTP model\")\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data used by model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vel = helper.get_velocity_for_agent(instance_token, sample_token)\n",
    "acc = helper.get_acceleration_for_agent(instance_token, sample_token)\n",
    "hcr = helper.get_heading_change_rate_for_agent(instance_token, sample_token)\n",
    "\n",
    "print(\"Velocity:\", vel)\n",
    "print(\"Acceleration:\", acc)\n",
    "print(\"Heading Change Rate:\", hcr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)\n",
    "plt.title(\"Visual REAL input for MTP model\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(future[:,0], future[:,1], 'ro-')\n",
    "plt.title(\"Trajectory Ground Truth used to train MTP model\")\n",
    "plt.grid()\n",
    "plt.axis('equal')\n",
    "# title for x and y axes\n",
    "plt.xlabel(\"X position (m)\")\n",
    "plt.ylabel(\"Y position (m)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lane-Level Map Information (not used in our prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The nuScenes Map API also provides detailed lane-level geometry, including lane\n",
    "centerlines, connectivity, curvature, and discretized arcline paths. These\n",
    "features are extremely useful for tasks such as route planning or lane\n",
    "prediction.\n",
    "\n",
    "However, the official nuScenes Prediction Challenge — and the MTP model we use\n",
    "in this project — operate exclusively in a rasterized bird’s-eye-view\n",
    "representation. Therefore, **lane-level map information is not used in our\n",
    "training or evaluation pipeline**.\n",
    "\n",
    "We include this small example only for educational purposes, to show the type of\n",
    "high-definition map features available in the dataset but not required for our\n",
    "trajectory prediction task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To help query lane center line information\n",
    "nusc_map = NuScenesMap(map_name='singapore-onenorth', dataroot=DATAROOT)\n",
    "\n",
    "# To get the closest lane to a location. Get_lane_record to know \n",
    "# internal data representation of a lane.\n",
    "\n",
    "# Conectivity of the lanes: get_outgoing_lanes, get_incoming_lane\n",
    "x, y, yaw = 395, 1095, 0\n",
    "closest_lane = nusc_map.get_closest_lane(x, y, radius=2)\n",
    "closest_lane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lane_record = nusc_map.get_arcline_path(closest_lane)\n",
    "lane_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nusc_map.get_incoming_lane_ids(closest_lane)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nusc_map.get_outgoing_lane_ids(closest_lane)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poses = arcline_path_utils.discretize_lane(lane_record, resolution_meters=1)\n",
    "poses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a query pose, find the closest pose on a lane\n",
    "closest_pose_on_lane, distance_along_lane = arcline_path_utils.project_pose_to_lane((x, y, yaw), lane_record)\n",
    "print(x, y, yaw)\n",
    "closest_pose_on_lane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_along_lane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find lenght of a lane\n",
    "arcline_path_utils.length_of_lane(lane_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute curvature of a lane\n",
    "# 0 means it is a straight lane.\n",
    "arcline_path_utils.get_curvature_at_distance_along_lane(distance_along_lane, lane_record)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
